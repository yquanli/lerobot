"""
SmolVLA è¯„ä¼°è„šæœ¬ - Piper 7D æœºå™¨äºº

è¿™ä¸ªè„šæœ¬å°è£…äº†è¯„ä¼°é…ç½®ï¼Œé¿å…æ¯æ¬¡éƒ½è¾“å…¥é•¿å‘½ä»¤è¡Œå‚æ•°ã€‚
åªéœ€ä¿®æ”¹ä¸‹é¢çš„é…ç½®å­—å…¸ï¼Œç„¶åè¿è¡Œï¼š
    python myscripts/eval/eval_smolvla.py

æ”¯æŒçš„æ“ä½œï¼š
    - è¯„ä¼°: python myscripts/eval/eval_smolvla.py
    - éªŒè¯é…ç½®: python myscripts/eval/eval_smolvla.py --validate-only
    - ç”Ÿæˆå‘½ä»¤: python myscripts/eval/eval_smolvla.py --print-command
"""

import argparse
import json
import subprocess
import sys
from dataclasses import dataclass, field
from pathlib import Path

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ° Python è·¯å¾„
project_root = Path(__file__).parent.parent.parent
sys.path.insert(0, str(project_root / "src"))


# ============================================================================
# è¯„ä¼°é…ç½® - åœ¨è¿™é‡Œä¿®æ”¹æ‚¨çš„è¯„ä¼°å‚æ•°
# ============================================================================

@dataclass
class EvalConfig:
    """SmolVLA è¯„ä¼°é…ç½®
    
    ç”¨äºåœ¨çœŸå®æœºå™¨äººä¸Šè¿è¡Œç­–ç•¥æ¨ç†å’Œè¯„ä¼°
    """
    
    # ========================================
    # 1. æœºå™¨äººé…ç½®
    # ========================================
    robot_type: str = "piper_follower"
    """æœºå™¨äººç±»å‹"""
    
    robot_id: str = "02"
    """æœºå™¨äºº IDï¼ˆç”¨äºè¯†åˆ«å…·ä½“çš„æœºå™¨äººè®¾å¤‡ï¼‰"""
    
    robot_control_mode: str = "policy"
    """æ§åˆ¶æ¨¡å¼
    - "policy": ä½¿ç”¨ç­–ç•¥æ§åˆ¶ï¼ˆè¯„ä¼°æ¨¡å¼ï¼‰
    - "teleop": ä½¿ç”¨é¥æ“ä½œæ§åˆ¶ï¼ˆå½•åˆ¶æ¨¡å¼ï¼‰
    """
    
    # ========================================
    # 2. ç­–ç•¥é…ç½®
    # ========================================
    policy_path: str = "outputs/train/piper_smolvla_transfer_cube_to_bin/checkpoints/last/pretrained_model"
    """ç­–ç•¥æ¨¡å‹è·¯å¾„
    
    å¯ä»¥æ˜¯ï¼š
    - æœ¬åœ°è·¯å¾„: "outputs/train/xxx/checkpoints/050000/pretrained_model"
    - HuggingFace repo: "username/model_name"
    """
    
    # ========================================
    # 3. æ•°æ®é›†é…ç½®ï¼ˆç”¨äºä¿å­˜è¯„ä¼°ç»“æœï¼‰
    # ========================================
    dataset_repo_id: str = "Sprinng/eval_transfer_cube_to_bin"
    """è¯„ä¼°æ•°æ®é›† repo IDï¼ˆç”¨äºä¿å­˜è¯„ä¼°ç»“æœï¼‰"""
    
    dataset_root: str | None = None
    """æ•°æ®é›†æ ¹ç›®å½•ï¼ˆé»˜è®¤ä½¿ç”¨ HuggingFace cacheï¼‰"""
    
    dataset_single_task: str = "Grab the cube and place it into the bin."
    """ä»»åŠ¡æè¿°ï¼ˆä¸è®­ç»ƒæ—¶ä¿æŒä¸€è‡´ï¼‰"""
    
    num_episodes: int = 5
    """è¯„ä¼°çš„ episode æ•°é‡"""
    
    episode_time_s: int = 60
    """æ¯ä¸ª episode çš„æœ€å¤§æ—¶é•¿ï¼ˆç§’ï¼‰"""
    
    reset_time_s: int = 30
    """episode ä¹‹é—´çš„é‡ç½®æ—¶é•¿ï¼ˆç§’ï¼‰"""
    
    fps: int = 30
    """å¸§ç‡"""
    
    # --- ç‰¹å¾åç§°æ˜ å°„ ---
    rename_map: dict[str, str] = field(default_factory=lambda: {
        "observation.images.top": "observation.images.camera1",
        "observation.images.wrist": "observation.images.camera2",
        "observation.images.side": "observation.images.camera3",
    })
    """æ•°æ®é›†ç‰¹å¾åç§°åˆ°ç­–ç•¥ç‰¹å¾åç§°çš„æ˜ å°„
    
    âš ï¸ é‡è¦ï¼šå¿…é¡»ä¸è®­ç»ƒæ—¶ä½¿ç”¨çš„ rename_map ä¸€è‡´ï¼
    """
    
    # ========================================
    # 4. æ˜¾ç¤ºå’Œæ—¥å¿—é…ç½®
    # ========================================
    display_data: bool = True
    """æ˜¯å¦æ˜¾ç¤ºæ‘„åƒå¤´ç”»é¢å’Œæ•°æ®å¯è§†åŒ–"""
    
    play_sounds: bool = True
    """æ˜¯å¦æ’­æ”¾è¯­éŸ³æç¤º"""
    
    # ========================================
    # 5. æ•°æ®ä¿å­˜é…ç½®
    # ========================================
    save_video: bool = True
    """æ˜¯å¦ä¿å­˜è§†é¢‘"""
    
    push_to_hub: bool = False
    """è¯„ä¼°å®Œæˆåæ˜¯å¦æ¨é€åˆ° HuggingFace Hub"""
    
    private: bool = False
    """å¦‚æœæ¨é€åˆ° Hubï¼Œæ˜¯å¦è®¾ä¸ºç§æœ‰"""
    
    tags: list[str] | None = field(default_factory=lambda: ["evaluation", "smolvla", "piper"])
    """æ•°æ®é›†æ ‡ç­¾"""
    
    # ========================================
    # 6. é«˜çº§é…ç½®
    # ========================================
    resume: bool = False
    """æ˜¯å¦ä»ç°æœ‰æ•°æ®é›†æ¢å¤è¯„ä¼°"""
    
    num_image_writer_processes: int = 0
    """å›¾åƒå†™å…¥è¿›ç¨‹æ•°"""
    
    num_image_writer_threads_per_camera: int = 4
    """æ¯ä¸ªæ‘„åƒå¤´çš„å›¾åƒå†™å…¥çº¿ç¨‹æ•°"""
    
    video_encoding_batch_size: int = 1
    """è§†é¢‘ç¼–ç æ‰¹æ¬¡å¤§å°"""


# ============================================================================
# è„šæœ¬é€»è¾‘
# ============================================================================

def config_to_cli_args(config: EvalConfig) -> list[str]:
    """å°†é…ç½®å¯¹è±¡è½¬æ¢ä¸ºå‘½ä»¤è¡Œå‚æ•°åˆ—è¡¨"""
    args = ["lerobot-record"]
    
    # æœºå™¨äººé…ç½®
    args.extend([
        f"--robot.type={config.robot_type}",
        f"--robot.id={config.robot_id}",
        f"--robot.control_mode={config.robot_control_mode}",
    ])
    
    # ç­–ç•¥é…ç½®
    args.append(f"--policy.path={config.policy_path}")
    
    # æ•°æ®é›†é…ç½®
    args.extend([
        f"--dataset.repo_id={config.dataset_repo_id}",
        f"--dataset.single_task=\"{config.dataset_single_task}\"",
        f"--dataset.num_episodes={config.num_episodes}",
        f"--dataset.episode_time_s={config.episode_time_s}",
        f"--dataset.reset_time_s={config.reset_time_s}",
        f"--dataset.fps={config.fps}",
        f"--dataset.video={str(config.save_video).lower()}",
        f"--dataset.push_to_hub={str(config.push_to_hub).lower()}",
        # f"--dataset.private={str(config.private).lower()}",
    ])
    
    if config.dataset_root:
        args.append(f"--dataset.root={config.dataset_root}")
    
    # ä»…åœ¨ä¸Šä¼ åˆ°hubæ—¶æœ‰ç”¨
    # if config.tags:
    #     tags_str = json.dumps(config.tags)
    #     args.append(f"--dataset.tags={tags_str}")
    
    # rename_mapï¼ˆé‡è¦ï¼ï¼‰
    if config.rename_map:
        rename_str = json.dumps(config.rename_map)
        args.append(f"--dataset.rename_map='{rename_str}'")
    
    # æ˜¾ç¤ºå’Œæ—¥å¿—é…ç½®
    args.extend([
        f"--display_data={str(config.display_data).lower()}",
        f"--play_sounds={str(config.play_sounds).lower()}",
    ])
    
    # é«˜çº§é…ç½®
    if config.resume:
        args.append("--resume=true")
    
    args.extend([
        f"--dataset.num_image_writer_processes={config.num_image_writer_processes}",
        f"--dataset.num_image_writer_threads_per_camera={config.num_image_writer_threads_per_camera}",
        f"--dataset.video_encoding_batch_size={config.video_encoding_batch_size}",
    ])
    
    return args


def validate_config(config: EvalConfig) -> bool:
    """éªŒè¯é…ç½®çš„æœ‰æ•ˆæ€§"""
    print("=" * 80)
    print("ğŸ” Validating Evaluation Configuration")
    print("=" * 80)
    
    errors = []
    warnings = []
    
    # æ£€æŸ¥ç­–ç•¥è·¯å¾„
    policy_path = Path(config.policy_path)
    if not policy_path.exists() and not config.policy_path.startswith(("http://", "https://", "hf://")):
        # å¯èƒ½æ˜¯ HuggingFace repoï¼Œä¸æ£€æŸ¥æœ¬åœ°è·¯å¾„
        if "/" not in config.policy_path:
            errors.append(f"Policy path not found and doesn't look like a HuggingFace repo: {config.policy_path}")
    
    # æ£€æŸ¥æ§åˆ¶æ¨¡å¼
    if config.robot_control_mode != "policy":
        warnings.append(
            f"robot_control_mode is '{config.robot_control_mode}', expected 'policy' for evaluation. "
            "Make sure this is intentional."
        )
    
    # æ£€æŸ¥ rename_map
    if not config.rename_map:
        warnings.append(
            "rename_map is empty. If your dataset uses different feature names than the policy, "
            "you must provide a rename_map."
        )
    
    # æ£€æŸ¥ episode é…ç½®
    if config.num_episodes <= 0:
        errors.append(f"num_episodes must be positive, got {config.num_episodes}")
    
    if config.episode_time_s <= 0:
        errors.append(f"episode_time_s must be positive, got {config.episode_time_s}")
    
    # æ£€æŸ¥ Hub é…ç½®
    if config.push_to_hub:
        if "/" not in config.dataset_repo_id:
            errors.append(
                f"dataset_repo_id should be in format 'username/dataset_name', got '{config.dataset_repo_id}'"
            )
    
    # æ‰“å°ç»“æœ
    if errors:
        print("\nâŒ Validation FAILED:")
        for err in errors:
            print(f"  â€¢ {err}")
        print()
        return False
    
    if warnings:
        print("\nâš ï¸  Warnings:")
        for warn in warnings:
            print(f"  â€¢ {warn}")
    
    print("\nâœ… Configuration validation passed!")
    print("=" * 80)
    return True


def print_config_summary(config: EvalConfig):
    """æ‰“å°é…ç½®æ‘˜è¦"""
    print("\n" + "=" * 80)
    print("ğŸ“‹ Evaluation Configuration Summary")
    print("=" * 80)
    
    print("\nğŸ¤– Robot:")
    print(f"  Type:                  {config.robot_type}")
    print(f"  ID:                    {config.robot_id}")
    print(f"  Control Mode:          {config.robot_control_mode}")
    
    print("\nğŸ§  Policy:")
    print(f"  Path:                  {config.policy_path}")
    
    print("\nğŸ“Š Dataset (Evaluation Results):")
    print(f"  Repo ID:               {config.dataset_repo_id}")
    print(f"  Task:                  {config.dataset_single_task}")
    print(f"  Num Episodes:          {config.num_episodes}")
    print(f"  Episode Time:          {config.episode_time_s}s")
    print(f"  Reset Time:            {config.reset_time_s}s")
    print(f"  FPS:                   {config.fps}")
    print(f"  Save Video:            {'âœ…' if config.save_video else 'âŒ'} {config.save_video}")
    
    if config.rename_map:
        print(f"\nğŸ”„ Feature Rename Map:")
        for old_name, new_name in config.rename_map.items():
            print(f"  {old_name}")
            print(f"    â†’ {new_name}")
    
    print("\nğŸ“º Display:")
    print(f"  Display Data:          {'âœ…' if config.display_data else 'âŒ'} {config.display_data}")
    print(f"  Play Sounds:           {'âœ…' if config.play_sounds else 'âŒ'} {config.play_sounds}")
    
    print("\nğŸ’¾ Saving:")
    print(f"  Push to Hub:           {'âœ…' if config.push_to_hub else 'âŒ'} {config.push_to_hub}")
    if config.push_to_hub:
        print(f"  Private:               {'âœ…' if config.private else 'âŒ'} {config.private}")
        print(f"  Tags:                  {config.tags}")
    
    if config.resume:
        print("\nâ™»ï¸  Resume:                âœ… True")
    
    print("\n" + "=" * 80)


def run_evaluation(config: EvalConfig, dry_run: bool = False):
    """è¿è¡Œè¯„ä¼°"""
    
    # æ‰“å°é…ç½®æ‘˜è¦
    print_config_summary(config)
    
    # éªŒè¯é…ç½®
    if not validate_config(config):
        print("\nâŒ Please fix the configuration errors above.")
        sys.exit(1)
    
    # ç”Ÿæˆå‘½ä»¤
    cmd_args = config_to_cli_args(config)
    
    # æ‰“å°å‘½ä»¤
    print("\n" + "=" * 80)
    print("ğŸš€ Evaluation Command")
    print("=" * 80)
    print("\n" + " \\\n  ".join(cmd_args))
    print("\n" + "=" * 80)
    
    if dry_run:
        print("\nâœ… Dry run completed. Command printed above.")
        return
    
    # ç¡®è®¤å¼€å§‹è¯„ä¼°
    print("\nâ³ Starting evaluation in 3 seconds... (Ctrl+C to cancel)")
    import time
    try:
        time.sleep(3)
    except KeyboardInterrupt:
        print("\nâŒ Evaluation cancelled by user.")
        sys.exit(0)
    
    # è¿è¡Œè¯„ä¼°
    print("\n" + "=" * 80)
    print("ğŸƒ Running Evaluation...")
    print("=" * 80 + "\n")
    
    try:
        cmd_str = " ".join(cmd_args)
        result = subprocess.run(cmd_str, shell=True, cwd=project_root)
        sys.exit(result.returncode)
    except KeyboardInterrupt:
        print("\n\nâš ï¸  Evaluation interrupted by user.")
        sys.exit(130)


def main():
    parser = argparse.ArgumentParser(
        description="SmolVLA Evaluation Script for Piper Robot",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
Examples:
  # ç›´æ¥å¼€å§‹è¯„ä¼°
  python myscripts/eval/eval_smolvla.py
  
  # åªéªŒè¯é…ç½®ï¼ˆä¸è¿è¡Œè¯„ä¼°ï¼‰
  python myscripts/eval/eval_smolvla.py --validate-only
  
  # æ‰“å°å‘½ä»¤ä½†ä¸è¿è¡Œ
  python myscripts/eval/eval_smolvla.py --print-command
  
  # ä½¿ç”¨ä¸åŒçš„ç­–ç•¥ checkpoint
  python myscripts/eval/eval_smolvla.py --policy-path outputs/train/xxx/checkpoints/050000/pretrained_model
  
  # è¯„ä¼°æ›´å¤š episodes
  python myscripts/eval/eval_smolvla.py --num-episodes 10
        """
    )
    
    parser.add_argument(
        "--validate-only",
        action="store_true",
        help="åªéªŒè¯é…ç½®ï¼Œä¸è¿è¡Œè¯„ä¼°"
    )
    parser.add_argument(
        "--print-command",
        action="store_true",
        help="æ‰“å°è¯„ä¼°å‘½ä»¤ä½†ä¸æ‰§è¡Œ"
    )
    parser.add_argument(
        "--policy-path",
        type=str,
        default=None,
        help="ç­–ç•¥æ¨¡å‹è·¯å¾„ï¼ˆè¦†ç›–é…ç½®ä¸­çš„é»˜è®¤å€¼ï¼‰"
    )
    parser.add_argument(
        "--num-episodes",
        type=int,
        default=None,
        help="è¯„ä¼°çš„ episode æ•°é‡ï¼ˆè¦†ç›–é…ç½®ä¸­çš„é»˜è®¤å€¼ï¼‰"
    )
    
    args = parser.parse_args()
    
    # åˆ›å»ºé…ç½®
    config = EvalConfig()
    
    # å¦‚æœæŒ‡å®šäº†å‘½ä»¤è¡Œå‚æ•°ï¼Œè¦†ç›–é…ç½®
    if args.policy_path:
        config.policy_path = args.policy_path
    if args.num_episodes:
        config.num_episodes = args.num_episodes
    
    # æ ¹æ®æ¨¡å¼è¿è¡Œ
    if args.validate_only:
        print_config_summary(config)
        if validate_config(config):
            print("\nâœ… Configuration is valid!")
        else:
            print("\nâŒ Configuration has errors!")
            sys.exit(1)
    elif args.print_command:
        run_evaluation(config, dry_run=True)
    else:
        run_evaluation(config, dry_run=False)


if __name__ == "__main__":
    main()