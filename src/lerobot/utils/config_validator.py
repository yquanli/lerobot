"""
é…ç½®éªŒè¯å·¥å…·æ¨¡å—

æä¾›ç­–ç•¥é…ç½®ä¸æ•°æ®é›†å…¼å®¹æ€§æ£€æŸ¥çš„å·¥å…·å‡½æ•°
"""

import logging
from typing import Any

import numpy as np
import torch

from lerobot.configs.types import FeatureType
from lerobot.datasets.utils import dataset_to_policy_features


logger = logging.getLogger(__name__)


class ConfigValidationError(Exception):
    """é…ç½®éªŒè¯å¤±è´¥æ—¶æŠ›å‡ºçš„å¼‚å¸¸"""
    pass


def validate_policy_dataset_compatibility(
    policy_cfg: Any,
    dataset_meta: Any,
    rename_map: dict[str, str] | None = None,
    raise_on_error: bool = True,
    verbose: bool = True,
) -> dict[str, Any]:
    """
    ç³»ç»Ÿæ€§éªŒè¯ç­–ç•¥é…ç½®ä¸æ•°æ®é›†çš„å…¼å®¹æ€§
    
    æ£€æŸ¥é¡¹ç›®ï¼š
    1. ç‰¹å¾ç»´åº¦åŒ¹é…ï¼ˆstate, action, imagesï¼‰
    2. ç‰¹å¾ç±»å‹åŒ¹é…
    3. ç‰¹å¾åç§°æ˜ å°„
    4. å½’ä¸€åŒ–é…ç½®
    5. è§‚æµ‹æ­¥æ•°å’ŒåŠ¨ä½œæ­¥æ•°
    
    Args:
        policy_cfg: ç­–ç•¥é…ç½®å¯¹è±¡
        dataset_meta: æ•°æ®é›†å…ƒæ•°æ®
        rename_map: ç‰¹å¾é‡å‘½åæ˜ å°„
        raise_on_error: æ˜¯å¦åœ¨å‘ç°é”™è¯¯æ—¶æŠ›å‡ºå¼‚å¸¸
        verbose: æ˜¯å¦æ‰“å°è¯¦ç»†ä¿¡æ¯
    
    Returns:
        éªŒè¯ç»“æœå­—å…¸ï¼ŒåŒ…å« 'passed', 'errors', 'warnings', 'info' å­—æ®µ
    
    Raises:
        ConfigValidationError: å¦‚æœ raise_on_error=True ä¸”å‘ç°ä¸¥é‡é”™è¯¯
    """
    result = {
        'passed': True,
        'errors': [],      # ä¸¥é‡é”™è¯¯ï¼ˆç»´åº¦ä¸åŒ¹é…ç­‰ï¼‰
        'warnings': [],    # è­¦å‘Šä¿¡æ¯ï¼ˆç¼ºå¤±ç‰¹å¾ç­‰ï¼‰
        'info': [],        # ä¸€èˆ¬ä¿¡æ¯
    }
    
    if verbose:
        logger.info("=" * 80)
        logger.info("ğŸ” Validating policy-dataset compatibility...")
        logger.info("=" * 80)
    
    # 1. è½¬æ¢æ•°æ®é›†ç‰¹å¾ä¸ºç­–ç•¥ç‰¹å¾æ ¼å¼
    dataset_features = dataset_to_policy_features(dataset_meta.features)
    
    # åº”ç”¨ rename_map
    if rename_map:
        if verbose:
            logger.info(f"ğŸ“ Applying rename_map: {rename_map}")
        renamed_features = {}
        for key, feature in dataset_features.items():
            new_key = rename_map.get(key, key)
            if new_key != key and verbose:
                logger.info(f"  âœ“ Renamed: {key} â†’ {new_key}")
            renamed_features[new_key] = feature
        dataset_features = renamed_features
    
    # 2. æ£€æŸ¥è¾“å…¥ç‰¹å¾ï¼ˆobservationsï¼‰
    if verbose:
        logger.info("\nğŸ“Š Checking INPUT features (observations)...")
        logger.info("-" * 80)
    
    for key, ds_feature in dataset_features.items():
        if ds_feature.type in [FeatureType.STATE, FeatureType.VISUAL]:
            if key in policy_cfg.input_features:
                policy_feature = policy_cfg.input_features[key]
                
                # æ£€æŸ¥ç±»å‹åŒ¹é…
                if policy_feature.type != ds_feature.type:
                    error_msg = (
                        f"Feature '{key}': type mismatch "
                        f"(policy={policy_feature.type}, dataset={ds_feature.type})"
                    )
                    result['errors'].append(error_msg)
                    if verbose:
                        logger.error(f"  âŒ {error_msg}")
                
                # æ£€æŸ¥ç»´åº¦åŒ¹é…
                if policy_feature.shape != ds_feature.shape:
                    error_msg = (
                        f"Feature '{key}': shape mismatch "
                        f"(policy={policy_feature.shape}, dataset={ds_feature.shape})"
                    )
                    result['errors'].append(error_msg)
                    if verbose:
                        logger.error(f"  âŒ {error_msg}")
                else:
                    if verbose:
                        logger.info(f"  âœ“ {key}: {ds_feature.type.name} {ds_feature.shape}")
            else:
                warning_msg = f"Feature '{key}' exists in dataset but missing in policy.input_features"
                result['warnings'].append(warning_msg)
                if verbose:
                    logger.warning(f"  âš ï¸  {warning_msg}")
    
    # æ£€æŸ¥ç­–ç•¥ä¸­å¤šä½™çš„ç‰¹å¾
    for key, policy_feature in policy_cfg.input_features.items():
        if key not in dataset_features:
            warning_msg = f"Feature '{key}' exists in policy but missing in dataset"
            result['warnings'].append(warning_msg)
            if verbose:
                logger.warning(f"  âš ï¸  {warning_msg}")
    
    # 3. æ£€æŸ¥è¾“å‡ºç‰¹å¾ï¼ˆactionsï¼‰
    if verbose:
        logger.info("\nğŸ“¤ Checking OUTPUT features (actions)...")
        logger.info("-" * 80)
    
    for key, ds_feature in dataset_features.items():
        if ds_feature.type == FeatureType.ACTION:
            if key in policy_cfg.output_features:
                policy_feature = policy_cfg.output_features[key]
                
                # æ£€æŸ¥ç±»å‹åŒ¹é…
                if policy_feature.type != ds_feature.type:
                    error_msg = (
                        f"Feature '{key}': type mismatch "
                        f"(policy={policy_feature.type}, dataset={ds_feature.type})"
                    )
                    result['errors'].append(error_msg)
                    if verbose:
                        logger.error(f"  âŒ {error_msg}")
                
                # æ£€æŸ¥ç»´åº¦åŒ¹é…
                if policy_feature.shape != ds_feature.shape:
                    error_msg = (
                        f"Feature '{key}': shape mismatch "
                        f"(policy={policy_feature.shape}, dataset={ds_feature.shape})"
                    )
                    result['errors'].append(error_msg)
                    if verbose:
                        logger.error(f"  âŒ {error_msg}")
                else:
                    if verbose:
                        logger.info(f"  âœ“ {key}: {ds_feature.type.name} {ds_feature.shape}")
            else:
                warning_msg = f"Feature '{key}' exists in dataset but missing in policy.output_features"
                result['warnings'].append(warning_msg)
                if verbose:
                    logger.warning(f"  âš ï¸  {warning_msg}")
    
    # 4. æ£€æŸ¥å½’ä¸€åŒ–é…ç½®
    if verbose:
        logger.info("\nğŸ”§ Checking normalization configuration...")
        logger.info("-" * 80)
    
    if hasattr(policy_cfg, 'normalization_mapping'):
        if verbose:
            logger.info(f"  Normalization mapping: {policy_cfg.normalization_mapping}")
        
        # æ£€æŸ¥æ¯ä¸ªç‰¹å¾æ˜¯å¦æœ‰å¯¹åº”çš„ç»Ÿè®¡æ•°æ®
        for key in {**policy_cfg.input_features, **policy_cfg.output_features}:
            if key in dataset_meta.stats:
                stats = dataset_meta.stats[key]
                feature = policy_cfg.input_features.get(key, policy_cfg.output_features.get(key))
                norm_mode = policy_cfg.normalization_mapping.get(feature.type, None)
                
                if norm_mode == "MEAN_STD":
                    if "mean" in stats and "std" in stats:
                        if verbose:
                            logger.info(f"  âœ“ {key}: has mean/std for MEAN_STD normalization")
                    else:
                        error_msg = f"Feature '{key}': missing mean/std stats for MEAN_STD normalization"
                        result['errors'].append(error_msg)
                        if verbose:
                            logger.error(f"  âŒ {error_msg}")
                elif norm_mode == "MIN_MAX":
                    if "min" in stats and "max" in stats:
                        if verbose:
                            logger.info(f"  âœ“ {key}: has min/max for MIN_MAX normalization")
                    else:
                        error_msg = f"Feature '{key}': missing min/max stats for MIN_MAX normalization"
                        result['errors'].append(error_msg)
                        if verbose:
                            logger.error(f"  âŒ {error_msg}")
            else:
                warning_msg = f"Feature '{key}': no stats found in dataset"
                result['warnings'].append(warning_msg)
                if verbose:
                    logger.warning(f"  âš ï¸  {warning_msg}")
    
    # 5. æ£€æŸ¥è§‚æµ‹å’ŒåŠ¨ä½œæ­¥æ•°
    if verbose:
        logger.info("\nâ±ï¸  Checking temporal configuration...")
        logger.info("-" * 80)
    
    temporal_config = {}
    for attr in ['n_obs_steps', 'chunk_size', 'n_action_steps']:
        if hasattr(policy_cfg, attr):
            value = getattr(policy_cfg, attr)
            temporal_config[attr] = value
            if verbose:
                logger.info(f"  {attr}: {value}")
    
    result['info'].append(f"Temporal config: {temporal_config}")
    
    # 6. æ£€æŸ¥å…¶ä»–é‡è¦é…ç½®
    if verbose:
        logger.info("\nâš™ï¸  Checking other policy configurations...")
        logger.info("-" * 80)
    
    important_attrs = [
        'device', 'use_amp', 'pretrained_path',
        'max_state_dim', 'max_action_dim',
        'freeze_vision_encoder', 'adapt_to_pi_aloha'
    ]
    
    other_config = {}
    for attr in important_attrs:
        if hasattr(policy_cfg, attr):
            value = getattr(policy_cfg, attr)
            other_config[attr] = value
            if verbose:
                logger.info(f"  {attr}: {value}")
    
    result['info'].append(f"Other config: {other_config}")
    
    # 7. æ±‡æ€»æ£€æŸ¥ç»“æœ
    if verbose:
        logger.info("\n" + "=" * 80)
        logger.info("ğŸ“‹ Validation Summary")
        logger.info("=" * 80)
    
    if result['errors']:
        result['passed'] = False
        if verbose:
            logger.error(f"âŒ Found {len(result['errors'])} critical error(s):")
            for error in result['errors']:
                logger.error(f"  â€¢ {error}")
    
    if result['warnings']:
        if verbose:
            logger.warning(f"âš ï¸  Found {len(result['warnings'])} warning(s):")
            for warning in result['warnings']:
                logger.warning(f"  â€¢ {warning}")
    
    if result['passed']:
        if verbose:
            logger.info("âœ… All critical checks passed! Policy and dataset are compatible.")
    else:
        if verbose:
            logger.error("âŒ Validation FAILED! Please fix the errors above.")
    
    if verbose:
        logger.info("=" * 80 + "\n")
    
    # å¦‚æœè®¾ç½®äº† raise_on_error ä¸”æœ‰é”™è¯¯ï¼ŒæŠ›å‡ºå¼‚å¸¸
    if raise_on_error and not result['passed']:
        raise ConfigValidationError(
            f"Policy-dataset compatibility check failed with {len(result['errors'])} error(s). "
            f"See logs above for details."
        )
    
    return result


def print_dataset_statistics(dataset_meta: Any, verbose: bool = True) -> dict[str, Any]:
    """
    æ‰“å°æ•°æ®é›†çš„è¯¦ç»†ç»Ÿè®¡ä¿¡æ¯
    
    Args:
        dataset_meta: æ•°æ®é›†å…ƒæ•°æ®
        verbose: æ˜¯å¦æ‰“å°è¯¦ç»†ä¿¡æ¯
    
    Returns:
        ç»Ÿè®¡ä¿¡æ¯å­—å…¸
    """
    stats_summary = {}
    
    if verbose:
        logger.info("=" * 80)
        logger.info("ğŸ“ˆ Dataset Statistics")
        logger.info("=" * 80)
    
    for key, stats in dataset_meta.stats.items():
        stats_summary[key] = {}
        if verbose:
            logger.info(f"\n{key}:")
        
        for stat_name, stat_value in stats.items():
            if isinstance(stat_value, (list, np.ndarray)):
                stat_array = np.array(stat_value)
                stats_summary[key][stat_name] = {
                    'shape': stat_array.shape,
                    'dtype': str(stat_array.dtype),
                }
                if verbose:
                    logger.info(f"  {stat_name}: shape={stat_array.shape}, dtype={stat_array.dtype}")
                    if stat_array.size <= 10:
                        logger.info(f"    values={stat_value}")
            else:
                stats_summary[key][stat_name] = stat_value
                if verbose:
                    logger.info(f"  {stat_name}: {stat_value}")
    
    if verbose:
        logger.info("=" * 80 + "\n")
    
    return stats_summary


def compare_policy_configs(
    config1: Any,
    config2: Any,
    config1_name: str = "Config 1",
    config2_name: str = "Config 2",
    verbose: bool = True,
) -> dict[str, Any]:
    """
    æ¯”è¾ƒä¸¤ä¸ªç­–ç•¥é…ç½®çš„å·®å¼‚
    
    Args:
        config1: ç¬¬ä¸€ä¸ªé…ç½®å¯¹è±¡
        config2: ç¬¬äºŒä¸ªé…ç½®å¯¹è±¡
        config1_name: ç¬¬ä¸€ä¸ªé…ç½®çš„åç§°
        config2_name: ç¬¬äºŒä¸ªé…ç½®çš„åç§°
        verbose: æ˜¯å¦æ‰“å°è¯¦ç»†ä¿¡æ¯
    
    Returns:
        å·®å¼‚ä¿¡æ¯å­—å…¸
    """
    differences = {
        'input_features': {},
        'output_features': {},
        'other_attributes': {},
    }
    
    if verbose:
        logger.info("=" * 80)
        logger.info("ğŸ”„ Comparing Policy Configurations")
        logger.info("=" * 80)
        logger.info(f"{config1_name} vs {config2_name}\n")
    
    # æ¯”è¾ƒ input_features
    if verbose:
        logger.info("ğŸ“Š Input Features:")
    
    all_input_keys = set(config1.input_features.keys()) | set(config2.input_features.keys())
    
    for key in sorted(all_input_keys):
        feat1 = config1.input_features.get(key)
        feat2 = config2.input_features.get(key)
        
        if feat1 is None:
            differences['input_features'][key] = f"Only in {config2_name}"
            if verbose:
                logger.warning(f"  {key}: Only in {config2_name}")
        elif feat2 is None:
            differences['input_features'][key] = f"Only in {config1_name}"
            if verbose:
                logger.warning(f"  {key}: Only in {config1_name}")
        elif feat1.shape != feat2.shape or feat1.type != feat2.type:
            diff_info = (
                f"{config1_name}: {feat1.type}[{feat1.shape}] vs "
                f"{config2_name}: {feat2.type}[{feat2.shape}]"
            )
            differences['input_features'][key] = diff_info
            if verbose:
                logger.warning(f"  {key}: {diff_info}")
        else:
            if verbose:
                logger.info(f"  {key}: âœ“ Same ({feat1.type}[{feat1.shape}])")
    
    # æ¯”è¾ƒ output_features
    if verbose:
        logger.info("\nğŸ“¤ Output Features:")
    
    all_output_keys = set(config1.output_features.keys()) | set(config2.output_features.keys())
    
    for key in sorted(all_output_keys):
        feat1 = config1.output_features.get(key)
        feat2 = config2.output_features.get(key)
        
        if feat1 is None:
            differences['output_features'][key] = f"Only in {config2_name}"
            if verbose:
                logger.warning(f"  {key}: Only in {config2_name}")
        elif feat2 is None:
            differences['output_features'][key] = f"Only in {config1_name}"
            if verbose:
                logger.warning(f"  {key}: Only in {config1_name}")
        elif feat1.shape != feat2.shape or feat1.type != feat2.type:
            diff_info = (
                f"{config1_name}: {feat1.type}[{feat1.shape}] vs "
                f"{config2_name}: {feat2.type}[{feat2.shape}]"
            )
            differences['output_features'][key] = diff_info
            if verbose:
                logger.warning(f"  {key}: {diff_info}")
        else:
            if verbose:
                logger.info(f"  {key}: âœ“ Same ({feat1.type}[{feat1.shape}])")
    
    # æ¯”è¾ƒå…¶ä»–é‡è¦å±æ€§
    if verbose:
        logger.info("\nâš™ï¸  Other Attributes:")
    
    important_attrs = [
        'n_obs_steps', 'chunk_size', 'n_action_steps',
        'device', 'use_amp', 'normalization_mapping',
        'max_state_dim', 'max_action_dim',
    ]
    
    for attr in important_attrs:
        val1 = getattr(config1, attr, None)
        val2 = getattr(config2, attr, None)
        
        if val1 != val2:
            diff_info = f"{config1_name}: {val1} vs {config2_name}: {val2}"
            differences['other_attributes'][attr] = diff_info
            if verbose:
                logger.warning(f"  {attr}: {diff_info}")
        else:
            if verbose:
                logger.info(f"  {attr}: âœ“ Same ({val1})")
    
    if verbose:
        logger.info("=" * 80 + "\n")
    
    return differences